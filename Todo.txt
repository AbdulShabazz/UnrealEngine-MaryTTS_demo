TODO: Improve cross-fade quality between phones (by increasing interframe connective resolution options) to improve prosody
TODO: Add respeecher support for (offline) voice-mapping
TODO: Refactor the MaryTTS demo to utilize our thread-safe ObserverThreadSafeClass
TODO: Support voice aggregation (crowd chorus)-, emotives-, mechanical voices-, whispers-, altered voices-, dipthongs and non-verbals
TODO: OPTION 1: Initially support phonetic spelling as a patch for choosing intonation or rhythm or prosodic character just from text input, 
	arbitrary text (eg. blaarp, froozle, dkskjbas) and heterphonic homographs (eg. tear, bow)
TODO: OPTION 2: Fully Support gTTS and remap the generated .mp3 to our internal (phone) library. 
TODO: OPTION 3: Formant modulation levels (eg. F0--F5) can be regulated by the flow of phonemes (modeled as signal transition keyframes) 
	sent through a state-machine (to adjust F0-F5 attack, decay, signal shape, etc.) for smoother (eg. vowels, consonants, diphthongs, etc.) 
	transitions between phones, similar to Deepmind's WaveNet and Tacotron based on WaveNet. This workflow can be modeled using Unreal Engine
	Blueprints for each phoneme. Each blueprints having tweakable parameters. The first phoneme in the train attaching a voice to it.
